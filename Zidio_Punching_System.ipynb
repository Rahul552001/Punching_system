{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286aa67c-ec8a-4b3c-910b-79a2e9c52a44",
   "metadata": {},
   "source": [
    "## First, install the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13b5838-fe15-498a-a893-c12b8bd4f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\rahul\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: face_recognition in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\rahul\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rahul\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\rahul\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python face_recognition numpy pandas matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40224b3b-baf9-47de-bfa6-f78abf6039ce",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46841fd-de7c-4a76-9a94-d2d821b87810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up directories for images and data\n",
    "if not os.path.exists('employee_faces'):\n",
    "    os.makedirs('employee_faces')\n",
    "\n",
    "if not os.path.exists('attendance_logs'):\n",
    "    os.makedirs('attendance_logs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610cb5d-d98c-427c-8e2a-d1729a32fb8e",
   "metadata": {},
   "source": [
    "## Register Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48a844-2b66-4bf8-be71-e42f24134c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "def register_employee():\n",
    "    # Get employee details from input\n",
    "    employee_id = input(\"Enter Employee ID: \")\n",
    "    employee_name = input(\"Enter Employee Name: \")\n",
    "    \n",
    "    # Create the directory to save employee images if it doesn't exist\n",
    "    if not os.path.exists('employee_faces'):\n",
    "        os.makedirs('employee_faces')\n",
    "    \n",
    "    # Open the webcam\n",
    "    video_capture = cv2.VideoCapture(0)  # 0 is usually the default webcam\n",
    "    \n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Capturing face for {employee_name} (ID: {employee_id})... Image will be saved in 5 seconds.\")\n",
    "    \n",
    "    start_time = time.time()  # Record the start time\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Failed to capture image.\")\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB (OpenCV uses BGR by default)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert the frame to a PIL image for display in Jupyter Notebook\n",
    "        img_pil = Image.fromarray(frame_rgb)\n",
    "        \n",
    "        # Display the frame in the notebook\n",
    "        clear_output(wait=True)  # Clear previous frames\n",
    "        display(img_pil)  # Display current frame\n",
    "        \n",
    "        # Check if 5 seconds have passed\n",
    "        if time.time() - start_time > 5:\n",
    "            # Save the current frame as the employee's image\n",
    "            image_path = f\"employee_faces/{employee_id}_{employee_name}.jpg\"\n",
    "            cv2.imwrite(image_path, frame)  # Save the image in the 'employee_faces' directory\n",
    "            print(f\"Image saved at {image_path}\")\n",
    "            break\n",
    "    \n",
    "    # Release the webcam\n",
    "    video_capture.release()\n",
    "\n",
    "# Call the function to start registration\n",
    "register_employee()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ccd5a-5400-4968-ae7e-b84819e88a43",
   "metadata": {},
   "source": [
    "## Facial Recognition for Check-In/Check-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5989151-50ad-4cb3-984a-194a56145619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 101_Rahul (ID: 101)\n",
      "Checking in 101_Rahul (ID: 101). Please wait...\n",
      "101_Rahul (ID: 101) checked in at 18:01:44\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking out.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "Checking out 101_Rahul (ID: 101). Please wait...\n",
      "101_Rahul (ID: 101) checked out at 18:06:44\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n",
      "Recognized: 101_Rahul (ID: 101)\n",
      "101_Rahul (ID: 101) must wait before checking in again.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 131\u001b[0m\n\u001b[0;32m    128\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Start the check-in/check-out system\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m check_in_check_out()\n",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m, in \u001b[0;36mcheck_in_check_out\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Find all face locations and encodings\u001b[39;00m\n\u001b[0;32m     64\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(rgb_small_frame)\n\u001b[1;32m---> 65\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_small_frame, face_locations)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face_encoding, face_location \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(face_encodings, face_locations):\n\u001b[0;32m     68\u001b[0m     matches \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mcompare_faces(known_faces, face_encoding)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Initialize video capture (0 for the default camera)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Load known faces and their names\n",
    "known_faces = []\n",
    "known_names = []\n",
    "attendance_log = {}  # Dictionary to track check-in and check-out status\n",
    "\n",
    "# Load your known faces and names from your dataset\n",
    "def load_known_faces(known_faces_directory):\n",
    "    for filename in os.listdir(known_faces_directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image = face_recognition.load_image_file(os.path.join(known_faces_directory, filename))\n",
    "            face_encoding = face_recognition.face_encodings(image)[0]\n",
    "            known_faces.append(face_encoding)\n",
    "            known_names.append(os.path.splitext(filename)[0])  # Use the filename as the name\n",
    "\n",
    "load_known_faces('employee_faces')  # Update the path\n",
    "\n",
    "# Function to log attendance to CSV (in the same row)\n",
    "def log_attendance(employee_id, name, status):\n",
    "    try:\n",
    "        # Read the existing attendance log\n",
    "        df = pd.read_csv(\"attendance.csv\")\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, create a new DataFrame with the required columns\n",
    "        df = pd.DataFrame(columns=[\"ID\", \"Employee Name\", \"Date\", \"Time\", \"Status\"])\n",
    "\n",
    "    # Log the attendance entry\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%Y-%m-%d')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "    new_row = {\n",
    "        \"ID\": employee_id,\n",
    "        \"Employee Name\": name,\n",
    "        \"Date\": date_str,\n",
    "        \"Time\": time_str,\n",
    "        \"Status\": status\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)  # Use pd.concat instead of append\n",
    "    df.to_csv(\"attendance.csv\", index=False)  # Save the updated DataFrame back to the CSV\n",
    "\n",
    "# Function to handle check-in and check-out process\n",
    "def check_in_check_out():\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame. Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR to RGB and resize for faster processing\n",
    "        rgb_small_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_small_frame = cv2.resize(rgb_small_frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Find all face locations and encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_names[first_match_index]\n",
    "                employee_id = name.split('_')[0]  # Extracting employee ID from name format\n",
    "\n",
    "                print(f\"Recognized: {name} (ID: {employee_id})\")\n",
    "                now = datetime.now()\n",
    "\n",
    "                # Check if employee has already checked in\n",
    "                if employee_id not in attendance_log:\n",
    "                    # First time seeing the face today - log check-in\n",
    "                    print(f\"Checking in {name} (ID: {employee_id}). Please wait...\")\n",
    "                    time.sleep(np.random.randint(3, 9))  # Wait for 3 to 8 seconds for recognition\n",
    "                    log_attendance(employee_id, name, status=\"Check-in\")\n",
    "                    attendance_log[employee_id] = {\"check_in\": now, \"check_out\": None}\n",
    "                    print(f\"{name} (ID: {employee_id}) checked in at {now.strftime('%H:%M:%S')}\")\n",
    "\n",
    "                elif employee_id in attendance_log:\n",
    "                    check_in_time = attendance_log[employee_id][\"check_in\"]\n",
    "                    check_out_time = attendance_log[employee_id][\"check_out\"]\n",
    "\n",
    "                    # If already checked in, check-out process\n",
    "                    if check_out_time is None:\n",
    "                        if now - check_in_time >= timedelta(minutes=5):  # Must wait 5 min after check-in\n",
    "                            print(f\"Checking out {name} (ID: {employee_id}). Please wait...\")\n",
    "                            time.sleep(np.random.randint(3, 9))  # Wait for 3 to 8 seconds for recognition\n",
    "                            log_attendance(employee_id, name, status=\"Check-out\")\n",
    "                            attendance_log[employee_id][\"check_out\"] = now\n",
    "                            print(f\"{name} (ID: {employee_id}) checked out at {now.strftime('%H:%M:%S')}\")\n",
    "\n",
    "                        else:\n",
    "                            print(f\"{name} (ID: {employee_id}) must wait before checking out.\")\n",
    "                    else:\n",
    "                        # Already checked out - allow check-in after 5 min cooldown\n",
    "                        if now - check_out_time >= timedelta(minutes=5):\n",
    "                            print(f\"Checking in {name} (ID: {employee_id}). Please wait...\")\n",
    "                            time.sleep(np.random.randint(3, 9))  # Wait for 3 to 8 seconds for recognition\n",
    "                            log_attendance(employee_id, name, status=\"Check-in\")\n",
    "                            attendance_log[employee_id][\"check_in\"] = now\n",
    "                            attendance_log[employee_id][\"check_out\"] = None  # Reset check-out status\n",
    "                            print(f\"{name} (ID: {employee_id}) checked in at {now.strftime('%H:%M:%S')}\")\n",
    "                        else:\n",
    "                            print(f\"{name} (ID: {employee_id}) must wait before checking in again.\")\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            top, right, bottom, left = [v * 4 for v in face_location]\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "        # Display the video feed with the recognized names\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Break the loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release video capture and close windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start the check-in/check-out system\n",
    "check_in_check_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12033c37-4d1a-488e-8f41-0a9317a3c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.3.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rahul\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from face_recognition) (10.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade face_recognition opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb4454-d709-421b-a9a1-8993c86756d5",
   "metadata": {},
   "source": [
    "## Spoof Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ffa668-3e3e-419f-b2b9-7bef8a58915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport numpy as np\\nimport face_recognition\\nimport datetime\\nimport os\\n\\n# Directory to store attendance data\\nattendance_file = \"attendance.csv\"\\n\\n# Function to check for spoofing (simple example)\\ndef is_spoof(frame):\\n    # Implement your spoof detection logic here\\n    # This is a placeholder that always returns False (no spoof detected)\\n    return False\\n\\n# Function to log attendance\\ndef log_attendance(name, status):\\n    current_time = datetime.datetime.now()\\n    with open(attendance_file, \\'a\\') as f:\\n        f.write(f\"{name},{current_time},{status}\\n\")\\n\\n# Main function for check-in and check-out\\ndef check_in_check_out():\\n    # Load known face encodings and their names\\n    known_face_encodings = []\\n    known_face_names = []\\n\\n    # Load your employee images here (Assuming images are named as ID_Name.jpg)\\n    employee_folder = \"employee_faces\"\\n    for filename in os.listdir(employee_folder):\\n        if filename.endswith(\".jpg\"):\\n            image_path = os.path.join(employee_folder, filename)\\n            image = face_recognition.load_image_file(image_path)\\n            encoding = face_recognition.face_encodings(image)[0]\\n            known_face_encodings.append(encoding)\\n            known_face_names.append(os.path.splitext(filename)[0])  # Use filename without extension as name\\n\\n    # Initialize video capture\\n    video_capture = cv2.VideoCapture(0)\\n\\n    while True:\\n        ret, frame = video_capture.read()\\n        if not ret:\\n            break\\n        \\n        # Convert the image from BGR to RGB\\n        rgb_small_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n\\n        # Detect face locations\\n        face_locations = face_recognition.face_locations(rgb_small_frame, model=\"hog\")\\n        \\n        if not face_locations:\\n            print(\"No faces detected.\")\\n            continue\\n\\n        # Detect face encodings based on the detected face locations\\n        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\\n\\n        if not face_encodings:\\n            print(\"No face encodings found.\")\\n            continue\\n        \\n        # Loop through each detected face\\n        for face_encoding, face_location in zip(face_encodings, face_locations):\\n            # Check if the detected face matches known faces\\n            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\\n            name = \"Unknown\"\\n\\n            # Use the known face with the smallest distance to the new face\\n            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\\n            best_match_index = np.argmin(face_distances)\\n            if matches[best_match_index]:\\n                name = known_face_names[best_match_index]\\n\\n            # Check for spoofing\\n            if is_spoof(frame):\\n                print(f\"Spoof detected for {name}!\")\\n                continue\\n            \\n            # Log attendance (check-in)\\n            log_attendance(name, \"Check-in\")\\n            print(f\"{name} checked in at {datetime.datetime.now()}.\")\\n\\n        # Display the resulting frame with the bounding box\\n        for (top, right, bottom, left) in face_locations:\\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\\n            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\\n\\n        # Show the frame\\n        cv2.imshow(\\'Video\\', frame)\\n\\n        # Break the loop on \\'q\\' key press\\n        if cv2.waitKey(1) & 0xFF == ord(\\'q\\'):\\n            break\\n\\n    # Release video capture and close windows\\n    video_capture.release()\\n    cv2.destroyAllWindows()\\n\\n# Run the check-in/check-out system\\nif __name__ == \"__main__\":\\n    # Ensure attendance file exists\\n    if not os.path.isfile(attendance_file):\\n        with open(attendance_file, \\'w\\') as f:\\n            f.write(\"Name,Timestamp,Status\\n\")  # Write headers\\n\\n    check_in_check_out()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Directory to store attendance data\n",
    "attendance_file = \"attendance.csv\"\n",
    "\n",
    "# Function to check for spoofing (simple example)\n",
    "def is_spoof(frame):\n",
    "    # Implement your spoof detection logic here\n",
    "    # This is a placeholder that always returns False (no spoof detected)\n",
    "    return False\n",
    "\n",
    "# Function to log attendance\n",
    "def log_attendance(name, status):\n",
    "    current_time = datetime.datetime.now()\n",
    "    with open(attendance_file, 'a') as f:\n",
    "        f.write(f\"{name},{current_time},{status}\\n\")\n",
    "\n",
    "# Main function for check-in and check-out\n",
    "def check_in_check_out():\n",
    "    # Load known face encodings and their names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    # Load your employee images here (Assuming images are named as ID_Name.jpg)\n",
    "    employee_folder = \"employee_faces\"\n",
    "    for filename in os.listdir(employee_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(employee_folder, filename)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            encoding = face_recognition.face_encodings(image)[0]\n",
    "            known_face_encodings.append(encoding)\n",
    "            known_face_names.append(os.path.splitext(filename)[0])  # Use filename without extension as name\n",
    "\n",
    "    # Initialize video capture\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the image from BGR to RGB\n",
    "        rgb_small_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect face locations\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame, model=\"hog\")\n",
    "        \n",
    "        if not face_locations:\n",
    "            print(\"No faces detected.\")\n",
    "            continue\n",
    "\n",
    "        # Detect face encodings based on the detected face locations\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        if not face_encodings:\n",
    "            print(\"No face encodings found.\")\n",
    "            continue\n",
    "        \n",
    "        # Loop through each detected face\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            # Check if the detected face matches known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            # Check for spoofing\n",
    "            if is_spoof(frame):\n",
    "                print(f\"Spoof detected for {name}!\")\n",
    "                continue\n",
    "            \n",
    "            # Log attendance (check-in)\n",
    "            log_attendance(name, \"Check-in\")\n",
    "            print(f\"{name} checked in at {datetime.datetime.now()}.\")\n",
    "\n",
    "        # Display the resulting frame with the bounding box\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Break the loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release video capture and close windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the check-in/check-out system\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure attendance file exists\n",
    "    if not os.path.isfile(attendance_file):\n",
    "        with open(attendance_file, 'w') as f:\n",
    "            f.write(\"Name,Timestamp,Status\\n\")  # Write headers\n",
    "\n",
    "    check_in_check_out()\"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea873db9-7f49-416a-aa75-6a33b17ff2d3",
   "metadata": {},
   "source": [
    "## Attendance log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f77188c-9a4b-432a-ad08-6cf158d8672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create attendance_logs directory if it doesn't exist\n",
    "if not os.path.exists('attendance_logs'):\n",
    "    os.makedirs('attendance_logs')\n",
    "\n",
    "def log_attendance(employee_id, name):\n",
    "    current_time = datetime.datetime.now()\n",
    "    date_str = current_time.strftime('%Y-%m-%d')\n",
    "    time_str = current_time.strftime('%H:%M:%S')\n",
    "    log_file = f'attendance_logs/{date_str}.csv'\n",
    "\n",
    "    # Determine if the employee can check in or check out\n",
    "    if check_already_checked_out(employee_id, log_file):\n",
    "        status = 'Check-in'\n",
    "    else:\n",
    "        status = 'Check-out'\n",
    "\n",
    "    # Log entry with ID, Name, Date, Time, and Status (Check-in/Check-out)\n",
    "    log_entry = {\n",
    "        'ID': employee_id,\n",
    "        'Name': name,\n",
    "        'Date': date_str,\n",
    "        'Time': time_str,\n",
    "        'Status': status\n",
    "    }\n",
    "\n",
    "    # Append entry to the log CSV\n",
    "    try:\n",
    "        log_df = pd.DataFrame([log_entry])\n",
    "        log_df.to_csv(log_file, mode='a', header=not os.path.exists(log_file), index=False)\n",
    "        print(f\"Attendance logged for {name} (ID: {employee_id}) at {time_str} ({status})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging attendance: {e}\")\n",
    "\n",
    "def check_already_checked_out(employee_id, log_file):\n",
    "    \"\"\"Check if the user has already checked out today.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(log_file):\n",
    "            # Read today's attendance log\n",
    "            log_df = pd.read_csv(log_file)\n",
    "            # Check the latest entry for the employee ID\n",
    "            if not log_df[log_df['ID'] == employee_id].empty:\n",
    "                last_entry = log_df[log_df['ID'] == employee_id].iloc[-1]\n",
    "                # If the last entry is 'Check-in', return True\n",
    "                return last_entry['Status'] == 'Check-out'\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking attendance: {e}\")\n",
    "    return True  # Assume true if file doesn't exist or no entry found\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdf6a9-a4be-443a-8628-84b5fad1668f",
   "metadata": {},
   "source": [
    "## Shift & Overtime Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1816c432-b86d-474b-9e62-fc0e71078430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name        Date  WorkedHours  Overtime\n",
      "0  Rahul Kumar  2024-10-05         24.0      16.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_overtime(attendance_df):\n",
    "    # Ensure the 'Time' column is in datetime format\n",
    "    attendance_df['Time'] = pd.to_datetime(attendance_df['Time'])\n",
    "\n",
    "    # Sort the dataframe by Name and Time to ensure proper calculation\n",
    "    attendance_df = attendance_df.sort_values(by=['Name', 'Time'])\n",
    "\n",
    "    # Extract date component for analysis\n",
    "    attendance_df['Date'] = attendance_df['Time'].dt.date\n",
    "\n",
    "    # Group by employee and date to calculate daily work hours\n",
    "    work_hours_per_day = []\n",
    "    \n",
    "    grouped = attendance_df.groupby(['Name', 'Date'])\n",
    "    \n",
    "    for (name, date), group in grouped:\n",
    "        # Sort by time to get in-out pairs\n",
    "        group = group.sort_values('Time')\n",
    "        \n",
    "        # Filter out \"Check-in\" and \"Check-out\" pairs\n",
    "        check_in_times = group[group['Status'] == 'Check-in']['Time']\n",
    "        check_out_times = group[group['Status'] == 'Check-out']['Time']\n",
    "        \n",
    "        # Ensure equal number of check-ins and check-outs\n",
    "        total_worked_seconds = 0\n",
    "        for check_in, check_out in zip(check_in_times, check_out_times):\n",
    "            total_worked_seconds += (check_out - check_in).total_seconds()\n",
    "        \n",
    "        # Convert seconds to hours\n",
    "        total_worked_hours = total_worked_seconds / 3600\n",
    "        \n",
    "        # Log daily work hours\n",
    "        work_hours_per_day.append({\n",
    "            'Name': name,\n",
    "            'Date': date,\n",
    "            'WorkedHours': total_worked_hours\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame from the daily work hours\n",
    "    work_hours_df = pd.DataFrame(work_hours_per_day)\n",
    "    \n",
    "    # Determine overtime (greater than 8 hours)\n",
    "    work_hours_df['Overtime'] = work_hours_df['WorkedHours'] - 8\n",
    "    overtime_df = work_hours_df[work_hours_df['Overtime'] > 0]\n",
    "    \n",
    "    return overtime_df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming attendance_data is your attendance DataFrame with the necessary columns.\n",
    "attendance_data = pd.DataFrame({\n",
    "    'ID': ['1001', '1001', '1001', '1001', '1001', '1001'],\n",
    "    'Name': ['Rahul Kumar', 'Rahul Kumar', 'Rahul Kumar', 'Rahul Kumar', 'Rahul Kumar', 'Rahul Kumar'],\n",
    "    'Date': ['2024-10-05'] * 6,\n",
    "    'Time': ['2024-10-05 09:00:00', '2024-10-05 17:00:00', \n",
    "             '2024-10-05 09:05:00', '2024-10-05 17:05:00', \n",
    "             '2024-10-05 09:10:00', '2024-10-05 17:10:00'],\n",
    "    'Status': ['Check-in', 'Check-out', \n",
    "               'Check-in', 'Check-out', \n",
    "               'Check-in', 'Check-out']\n",
    "})\n",
    "\n",
    "# Convert time strings to datetime\n",
    "attendance_data['Time'] = pd.to_datetime(attendance_data['Time'])\n",
    "\n",
    "# Calculate overtime\n",
    "overtime_df = calculate_overtime(attendance_data)\n",
    "\n",
    "# Display the results\n",
    "print(overtime_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56246de0-cba8-4144-84b6-63b39d57690a",
   "metadata": {},
   "source": [
    "## Generate Attendance Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2be37845-ea66-402c-888c-328522524647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preview:\n",
      "    ID  Employee Name        Date      Time     Status\n",
      "0   ID  Employee Name        Date      Time     Status\n",
      "1  101      101_Rahul  2024-10-06  03:23:11   Check-in\n",
      "2  101      101_Rahul  2024-10-06  03:28:36  Check-out\n",
      "3  101      101_Rahul  2024-10-06  03:35:15   Check-in\n",
      "Check-in Data Preview:\n",
      "    ID Employee Name        Date      Time    Status           Timestamp\n",
      "1  101     101_Rahul  2024-10-06  03:23:11  Check-in 2024-10-06 03:23:11\n",
      "3  101     101_Rahul  2024-10-06  03:35:15  Check-in 2024-10-06 03:35:15\n",
      "Check-out Data Preview:\n",
      "    ID Employee Name        Date      Time     Status           Timestamp\n",
      "2  101     101_Rahul  2024-10-06  03:28:36  Check-out 2024-10-06 03:28:36\n",
      "Merged Report Preview:\n",
      "  ID_in Employee Name     Date_in   Time_in Status_in           Timestamp  \\\n",
      "0   101     101_Rahul  2024-10-06  03:23:11  Check-in 2024-10-06 03:23:11   \n",
      "1   101     101_Rahul  2024-10-06  03:35:15  Check-in 2024-10-06 03:35:15   \n",
      "\n",
      "  ID_out    Date_out  Time_out Status_out  \n",
      "0    101  2024-10-06  03:28:36  Check-out  \n",
      "1    NaN         NaN       NaN        NaN  \n",
      "Merged report columns: ['ID_in', 'Employee Name', 'Date_in', 'Time_in', 'Status_in', 'Timestamp', 'ID_out', 'Date_out', 'Time_out', 'Status_out']\n",
      "Warning: No matching check-out records found for some check-ins.\n",
      "  ID_in Employee Name     Date_in   Time_in\n",
      "0   101     101_Rahul  2024-10-06  03:23:11\n",
      "1   101     101_Rahul  2024-10-06  03:35:15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_attendance_report(csv_file):\n",
    "    \"\"\"\n",
    "    Generates an attendance report based on check-in/check-out times from your CSV format.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_file (str): Path to the CSV file containing attendance logs.\n",
    "    \n",
    "    Returns:\n",
    "    - A pandas DataFrame containing the report.\n",
    "    \"\"\"\n",
    "    # Read the attendance data from the CSV file\n",
    "    try:\n",
    "        attendance_data = pd.read_csv(csv_file, header=None, names=[\"ID\", \"Employee Name\", \"Date\", \"Time\", \"Status\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Check if the data was read correctly\n",
    "    if attendance_data.empty or attendance_data.shape[0] <= 1:  # Ensuring there's data beyond the header\n",
    "        print(\"The CSV file is empty or the format is incorrect.\")\n",
    "        return None\n",
    "\n",
    "    # Debug: Display the first few rows of the data\n",
    "    print(\"Data preview:\")\n",
    "    print(attendance_data.head())\n",
    "\n",
    "    # Convert 'Date' and 'Time' to datetime for easier manipulation\n",
    "    try:\n",
    "        # Specify the date and time formats explicitly\n",
    "        attendance_data['Timestamp'] = pd.to_datetime(\n",
    "            attendance_data['Date'] + ' ' + attendance_data['Time'],\n",
    "            format='%Y-%m-%d %H:%M:%S',\n",
    "            errors='coerce'  # This will convert unparseable formats to NaT\n",
    "        )\n",
    "        # Drop rows where the timestamp conversion failed\n",
    "        attendance_data.dropna(subset=['Timestamp'], inplace=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting date and time to datetime: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Separate the check-ins and check-outs\n",
    "    check_in_data = attendance_data[attendance_data['Status'].str.lower() == 'check-in']\n",
    "    check_out_data = attendance_data[attendance_data['Status'].str.lower() == 'check-out']\n",
    "\n",
    "    # Debug: Display check-in and check-out data\n",
    "    print(\"Check-in Data Preview:\")\n",
    "    print(check_in_data)\n",
    "    \n",
    "    print(\"Check-out Data Preview:\")\n",
    "    print(check_out_data)\n",
    "\n",
    "    # Merge the check-in and check-out data based on 'Employee Name' and the nearest timestamps\n",
    "    report = pd.merge_asof(check_in_data.sort_values('Timestamp'), \n",
    "                           check_out_data.sort_values('Timestamp'), \n",
    "                           on='Timestamp', \n",
    "                           by='Employee Name', \n",
    "                           direction='forward', \n",
    "                           suffixes=('_in', '_out'))\n",
    "\n",
    "    # Debug: Display the merged report\n",
    "    print(\"Merged Report Preview:\")\n",
    "    print(report)\n",
    "\n",
    "    # Debug: Print the actual column names in the merged report\n",
    "    print(\"Merged report columns:\", report.columns.tolist())\n",
    "\n",
    "    # Check if merged report has 'Timestamp_out'\n",
    "    if 'Timestamp_out' not in report.columns:\n",
    "        print(\"Warning: No matching check-out records found for some check-ins.\")\n",
    "        # Return only available columns\n",
    "        return report[['ID_in', 'Employee Name', 'Date_in', 'Time_in']]\n",
    "\n",
    "    # Calculate the total working hours by subtracting the check-in time from the check-out time\n",
    "    report['Total_Working_Hours'] = (report['Timestamp_out'] - report['Timestamp_in']).dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "    # Return the attendance report with relevant columns\n",
    "    return report[['ID_in', 'Employee Name', 'Date_in', 'Timestamp_in', 'Timestamp_out', 'Total_Working_Hours']]\n",
    "\n",
    "# Example usage: generate the attendance report\n",
    "attendance_report = generate_attendance_report('attendance.csv')\n",
    "\n",
    "# Display the report\n",
    "if attendance_report is not None:\n",
    "    print(attendance_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bce0cc91-c67a-4d4b-a987-25b8bbad311d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17992\\2173216782.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'attendance.csv'\u001b[0m  \u001b[1;31m# Update the CSV file path as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0mattendance_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_attendance_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Generate reports for a specific date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2024-10-06'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17992\\2173216782.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(csv_file)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcheck_in_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattendance_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattendance_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Check-in'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mcheck_out_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattendance_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattendance_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Check-out'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Merge check-in and check-out data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_in_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_out_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_in'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Convert timestamps to datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mreport\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp_in'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp_in'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         )\n\u001b[0;32m    168\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_attendance_data(csv_file):\n",
    "    # Load attendance data from CSV file\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "def generate_attendance_report(csv_file):\n",
    "    attendance_data = load_attendance_data(csv_file)\n",
    "\n",
    "    # Check if 'Status' column exists\n",
    "    if 'Status' not in attendance_data.columns:\n",
    "        raise KeyError(\"The column 'Status' is missing from the attendance data.\")\n",
    "\n",
    "    # Separate check-in and check-out records\n",
    "    check_in_data = attendance_data[attendance_data['Status'] == 'Check-in']\n",
    "    check_out_data = attendance_data[attendance_data['Status'] == 'Check-out']\n",
    "\n",
    "    # Merge check-in and check-out data\n",
    "    report = pd.merge(check_in_data, check_out_data, on='Name', suffixes=('_in', '_out'))\n",
    "    \n",
    "    # Convert timestamps to datetime\n",
    "    report['Timestamp_in'] = pd.to_datetime(report['Timestamp_in'], errors='coerce')\n",
    "    report['Timestamp_out'] = pd.to_datetime(report['Timestamp_out'], errors='coerce')\n",
    "\n",
    "    # Calculate total working hours\n",
    "    report['Total_Working_Hours'] = (report['Timestamp_out'] - report['Timestamp_in']).dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "    return report[['Name', 'Timestamp_in', 'Timestamp_out', 'Total_Working_Hours']]\n",
    "\n",
    "def generate_daily_report(attendance_data, date):\n",
    "    daily_data = attendance_data[attendance_data['Timestamp_in'].dt.date == pd.to_datetime(date).date()]\n",
    "    shift_start_time = pd.to_datetime('09:00:00').time()  # Adjust as necessary\n",
    "\n",
    "    late_arrivals = daily_data[daily_data['Timestamp_in'].dt.time > shift_start_time]\n",
    "    early_departures = daily_data[daily_data['Timestamp_out'].dt.time < pd.to_datetime('17:00:00').time()]  # Adjust as necessary\n",
    "\n",
    "    report = {\n",
    "        'Total_Attendance': len(daily_data),\n",
    "        'Late_Arrivals': len(late_arrivals),\n",
    "        'Early_Departures': len(early_departures),\n",
    "        'Total_Working_Hours': daily_data['Total_Working_Hours'].sum()\n",
    "    }\n",
    "    return report\n",
    "\n",
    "def generate_weekly_report(attendance_data, date):\n",
    "    date = pd.to_datetime(date)\n",
    "    week_start = date - pd.Timedelta(days=date.weekday())  # Start of the week (Monday)\n",
    "    week_end = week_start + pd.Timedelta(days=6)  # End of the week (Sunday)\n",
    "\n",
    "    weekly_data = attendance_data[(attendance_data['Timestamp_in'] >= week_start) & (attendance_data['Timestamp_in'] <= week_end)]\n",
    "\n",
    "    report = {\n",
    "        'Total_Attendance': len(weekly_data),\n",
    "        'Total_Working_Hours': weekly_data['Total_Working_Hours'].sum()\n",
    "    }\n",
    "    return report\n",
    "\n",
    "def generate_monthly_report(attendance_data, date):\n",
    "    month_start = pd.to_datetime(date).replace(day=1)\n",
    "    next_month_start = (month_start + pd.DateOffset(months=1)).replace(day=1)\n",
    "\n",
    "    monthly_data = attendance_data[(attendance_data['Timestamp_in'] >= month_start) & (attendance_data['Timestamp_in'] < next_month_start)]\n",
    "\n",
    "    report = {\n",
    "        'Total_Attendance': len(monthly_data),\n",
    "        'Total_Working_Hours': monthly_data['Total_Working_Hours'].sum()\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# Example usage\n",
    "csv_file = 'attendance.csv'  # Update the CSV file path as needed\n",
    "attendance_report = generate_attendance_report(csv_file)\n",
    "\n",
    "# Generate reports for a specific date\n",
    "date = '2024-10-06'\n",
    "daily_report = generate_daily_report(attendance_report, date)\n",
    "print(\"Daily Report:\", daily_report)\n",
    "\n",
    "weekly_report = generate_weekly_report(attendance_report, date)\n",
    "print(\"Weekly Report:\", weekly_report)\n",
    "\n",
    "monthly_report = generate_monthly_report(attendance_report, date)\n",
    "print(\"Monthly Report:\", monthly_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f148e-dc07-492b-95a8-d322656843b4",
   "metadata": {},
   "source": [
    "## Data Analysis & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0aeb4d32-36f3-4cc0-831f-981c4e64b1a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'attendance_logs/2024-10-02.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load sample attendance data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m attendance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattendance_logs/2024-10-02.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m analyze_trends(attendance_df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'attendance_logs/2024-10-02.csv'"
     ]
    }
   ],
   "source": [
    "def analyze_trends(attendance_df):\n",
    "    # Calculate absenteeism trends\n",
    "    absent_days = attendance_df.groupby('Name')['Date'].nunique()\n",
    "\n",
    "    # Plot absenteeism\n",
    "    absent_days.plot(kind='bar')\n",
    "    plt.title('Absenteeism Trends')\n",
    "    plt.show()\n",
    "\n",
    "# Load sample attendance data\n",
    "attendance_df = pd.read_csv('attendance_logs/2024-10-02.csv')\n",
    "analyze_trends(attendance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56917be-91ca-412e-b37a-e1b26b5b9237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
